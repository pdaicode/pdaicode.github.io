<link rel="shortcut icon" href="./support/DrStrange_dark.png"/>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0034)https://speednet-cvpr20.github.io/ -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>
Self-supervised Spatiotemporal Representation Learning by Exploiting Video Continuity
</title>
<link href="./support/style.css" rel="stylesheet" type="text/css">

<!-- Global site tag (gtag.js) - Google Analytics -->

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-163559140-1');
</script>
  
</head>
<body>
<div class="container">
  <p>&nbsp;</p>
  <p><span class="title">Awesome 3D Gaussians</span></p>
  <br>
  <table border="0" align="center" class="authors">
    <tbody><tr align="center">
	    <td>A summary of 3D Gaussian Splatting Resources</td>
	  
    </tr>
  </tbody></table>
  
  
  <br>
  
  <br>
  <table width="200" border="0" align="center">
    <tbody><tr>
      <td><img src="./support/cpnet.png" width="900" alt=""></td>
    </tr>
    <tr>
      <td class="caption"><p>Illustration of the continuity-aware pretext task (a) and the Continuity Perception Network (b). CPNet is composed of
			a three-branch architecture solving continuity justification, discontinuity localization, and missing section approximation tasks.</p></td>
    </tr>
  </tbody></table>
  <br>
  <p><span class="section">Abstract</span></p>
  <p>
  Recent self-supervised video representation learning methods have found significant success by exploring essential properties of videos, e.g. speed, temporal order, etc. This work exploits an essential yet under-explored property of videos, the video continuity, 
  to obtain supervision signals for self-supervised representation learning. Specifically, we formulate three novel continuity-related pretext tasks, i.e. continuity justification, discontinuity localization, and missing section approximation, 
  that jointly supervise a shared backbone for video representation learning. This self-supervision approach, termed as Continuity Perception Network (CPNet), solves the three tasks altogether and encourages the backbone network to learn local and long-ranged motion and context representations. 
  It outperforms prior arts on multiple downstream tasks, such as action recognition, video retrieval, and action localization. Additionally, the video continuity can be complementary to other coarse-grained video properties for representation learning, 
  and integrating the proposed pretext task to prior arts can yield much performance gains.
  <br>
  </p>
  <p class="section">&nbsp;</p>
  
  

  <p class="section">Paper</p>
  <table width="940" border="0">
    <tbody>
      <tr>
        <td width="175" height="202"><a href="https://arxiv.org/pdf/2004.06130.pdf"><img src="./support/cpnet_cover.png" alt="" width="175" height="211"></a></td>
        <td width="5">&nbsp;</td>
        <td width="645"><p>"Self-supervised Spatiotemporal Representation Learning by Exploiting Video Continuity",<br>
            Hanwen Liang, Niamul Quader, Zhixiang Chi, Lizhe Chen, Peng Dai, Juwei Lu, Yang Wang<br>
        </p>
		<p>
          </strong>AAAI 2022<strong>          </strong></em><br>
          </p>
        <p>[<a href="https://arxiv.org/abs/2112.05883">Arxiv</a>] [<a href="https://www.aaai.org/AAAI22Papers/AAAI-6231.LiangH.pdf">AAAI</a>]</p></td>
      </tr>
    </tbody>
  </table>
  
  <br>
  
  <p class="section">&nbsp;</p>
  <p align="center" class="date">Last updated: April 2022</p>
</div>


</body></html>