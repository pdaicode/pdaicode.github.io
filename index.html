<link rel="shortcut icon" href="./images0/hw-icon.jpg"/>

<head>
  <title>Peng's website</title>
  <meta name="description" content="free website template" />
  <meta http-equiv="Content-type" content="text/html; charset=utf-8"> 
  <link rel="stylesheet" type="text/css" href="css/style.css" />
  <script type="text/javascript" src="js/jquery.min.js"></script>
  <script type="text/javascript" src="js/image_slide.js"></script>
</head>

<body>
  <div id="main">
    <div id="header">
      <div id="banner">
	    <a href="#">Welcome to Peng's website</a>
	  </div>
      <div id="menubar">
        <ul id="menu">
          <li style="font-size:120%"><a href="index.html">Home</a></li>
		  <li style="font-size:120%"><a href="members.html">Members</a></li>
          <li style="font-size:120%"><a href="publications.html">Publications</a></li>
		  <li style="font-size:120%"><a href="news.html">News</a></li>
		  <li style="font-size:120%"><a href="3DGS.html"><strong>3DGS</strong></a></li>
        </ul>
      </div>
    </div>
	<!--
	<div class="sidebar_containerL">
		<div class="sidebarL">
			<a class="twitter-timeline" href="https://twitter.com/declanide" data-widget-id="634733354391347200">Tweets by @declanide</a>
	<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
		</div>
	</div>
	-->
	
    <div id="site_content">
            
	  <div id="content">
        <div class="content_item">
			<!-- <h1 class="section-heading">Derek Peng Dai</h1> -->
			<div style="float:left; height: 181px; border: 2px solid #CCC; margin-right: 10px; padding: 5px;">
			<img  height="180" width="200" src="./images0/dp2.png" alt="image" /></div>
			
			<p>My name is Peng Dai. I am broadly interested in Data Mining and Machine Learning, specifically in areas of Deep Learning, Computer Vision, Bioinformatics, 
			and Audio Signal Processing.</p>
			<p>
				My new <a href="gpt/gindex.html" target="_blank"><b>[GPT-Page]</b></a> created with GPT-4, by using interactive prompts.
			</p>
			<p>
				<a href="https://scholar.google.ca/citations?user=pOpgtRgAAAAJ&hl=en" target="_blank">Google Scholar</a>,
				<a href="https://www.linkedin.com/in/peng-dai-6b426120/" target="_blank">LinkedIn</a>,
				<a href="https://www.researchgate.net/profile/Peng_Dai6" target="_blank">ResearchGate</a>
			</p>
			<p>
				We're hiring <a href="https://jobs.smartrecruiters.com/HuaweiTechnologiesCanadaCoLtd/743999779107464-computer-vision-research-scientist-phd-?trid=463ac537-35c8-4256-8fe4-47ea285de0a6" target="_blank"><b>PhD</b> fresh graduates</a>, 
				Postdocs, and <b>interns</b>! Feel free to contact me if you're interested.
			</p>

			<p>
			Currently, I'm working as a <b>Sr. Staff Scientist</b> with Huawei Canada Research Center, Noah's Ark Lab, working on deep learning with special focus on computer vision applications. 
			I'm leading the video understanding team. I'm Senior Member of IEEE. Since Nov 2021, I'm the Vice-Chair of IEEE Engineering and Human Environment joint chapter - Toronto. I'm also with 
			<a href="https://www.ieeetoronto.ca/chapters/computer/" target="_blank"> IEEE Computer Chapter - Toronto</b></a>.
			From 2018 to 2020, I was an <a href="https://www.ryerson.ca/electrical-computer-biomedical/people/adjunct-emeritus/" target="_blank"> <b>Adjunct Professor</b></a> at <a href="https://www.ee.ryerson.ca/" target="_blank"> 
			Department of Electrical, Computer & Biomedical Engineering</a>, Ryerson University. I'm in close collaboration with <a href="https://med.szu.edu.cn/Item/2076.aspx" target="_blank"> Prof Huijun Ding</a> at Shenzhen University.
			</p>
			
			<h2><span style="margin-bottom: -40px"><strong>Top News</strong> (<a href="news.html">complete list</a>)</span></h2>
				<p><li style="font-size:15px;margin-top: -20px;margin-bottom: -20px;line-height:2"> [Product] 9/2023, Our work in <strong>Neural Rendering</strong> is featured in <a href="https://www.huawei.com/en/events/huaweiconnect" target="_blank"> 
					Huawei Connect 2023</a>.
					</li></p>

				<p><li style="font-size:15px;margin-top: -10px;margin-bottom: -20px;line-height:2"> [Research] 9/2023, 1 paper, <a href="https://twitter.com/PengDai_ca/status/1705206450702729313" target="_blank"> 
					Decorate3D: Text-Driven High-Quality Texture Generation for Mesh Decoration in the Wild</a>, accepted at  
					<a href="https://nips.cc/" target="_blank"><strong>NeurIPS 2023</strong></a>.
					</li></p>
					
				<p><li style="font-size:15px;margin-top: -10px;margin-bottom: -20px;line-height:2"> [Research] 8/2023, 1 paper, HiVLP: Hierarchical Interactive Video-Language Pre-Training, accepted at  
					<a href="https://cvpr2023.thecvf.com/" target="_blank"><strong>ICCV 2023</strong></a>.
					</li></p>

				<p><li style="font-size:15px;margin-top: -10px;margin-bottom: -20px;line-height:2"> [Research] 3/2023, <a href="https://twitter.com/PengDai_ca/status/1630320727483203584" target="_blank"> 1 paper</a> accepted at  
					<a href="https://cvpr2023.thecvf.com/" target="_blank"><strong>CVPR2023</strong></a>.
					</li></p>
				
				<p><li style="font-size:15px;margin-top: -10px;margin-bottom: -20px;line-height:2"> [Research] 7/2022, 1 paper accepted at  
					<a href="https://eccv2022.ecva.net/">ECCV2022</a>.
					</li></p>
				
				<p><li style="font-size:15px;margin-top: -10px;margin-bottom: -20px;line-height:2"> [Research] 6/2022, our team win the 2nd place in 2022 
					<a href="http://activity-net.org/challenges/2022/tasks/anet_localization.html">ActivityNet Temporal Action Localization Challenge</a>.
					</li></p>
					
				<p><li style="font-size:15px; margin-top: -10px; margin-bottom: -20px;line-height:2"> [Research] 2/2022, Our paper, <a href="https://arxiv.org/abs/2112.11547" target="_blank">
					<span style="font-style:italic">"Decompose the Sounds and Pixels, Recompose the Events"</span></a>, has been chosen as <b>Oral</b> presentation at 
					<a href="https://aaai.org/Conferences/AAAI-22/" target="_blank">AAAI2022</a> (Feb 26, 10:30am-11:45am PST)! Also featured in <a href="https://mp.weixin.qq.com/s/u1z9C6wwgNJRnGba_0njrw" target="_blank">Noah's Ark official blog</a>! 
					[<a href="./projects/edrnet.html" target="_blank">Project Page</a>]
					</li></p>
				<p><li style="font-size:15px; margin-top: -5px; margin-bottom: -20px"> [Research] 2/2022, Noah's Ark Lab has open sourced a large-scale multi-modality chinese dataset
					<a href="https://wukong-dataset.github.io/wukong-dataset/index.html" target="_blank">Wukong</a>. <a href="https://arxiv.org/abs/2202.06767">arxiv</a>.
					</li></p>
				<p><li style="font-size:15px;margin-bottom: -20px"> [Research] 12/2021, two papers accepted by
					<a href="https://aaai.org/Conferences/AAAI-22/" target="_blank">AAAI2022</a>. [<a href="./projects/cpnet.html" target="_blank"><strong>CPNet</strong></a>] [<a href="./projects/edrnet.html" target="_blank"><strong>EDRNet</strong></a>]
					</li></p>
				<p><li style="font-size:15px;margin-bottom: -20px"> [IEEE] 12/2021, IEEE Engineering and Human Environment joint Chapter is organizing a 
					<a href="https://events.vtools.ieee.org/m/288981" target="_blank">Talk</a>.
					</li></p>
				<p><li style="font-size:15px;margin-bottom: -20px"> [Product] 11/2021, Huawei Intelligent Education Solution in the 
					<a href="https://mp.weixin.qq.com/s/RLt14GEl5wuD0U2OD_8aWQ" target="_blank">News</a> (Chinese).
					</li></p>
				<p><li style="font-size:15px;margin-bottom: -20px"> [Product] 10/2021, Our collaboration team developed 
					<a href="https://youtu.be/kVhq8d5T9PI?t=1179" target="_blank">Sign Language Digital Avatar</a>. </li></p>
				<p><li style="font-size:15px;margin-bottom: -20px"> [Commercial] 10/2021, we become the Spotlight sponsor of 
					<a href="http://iccv2021.thecvf.com/" target="_blank">ICCV2021</a>.</li></p>
				<p><li style="font-size:15px;margin-bottom: -20px"> [Research] 07/2021, two papers accepted by 
					<a href="http://iccv2021.thecvf.com/">ICCV2021</a>: <a href="https://www.youtube.com/watch?v=uJqN-7cLomI" target="_blank"><b>CSA Video</b></a>, [<a href="./projects/activitynet.html" target="_blank"><strong>Project Page</strong></a>] </a> </li></p> 
				<p><li style="font-size:15px;margin-bottom: -20px"> [Product] 07/2021, Petal Search for Sports Highlights, 
					<a href="https://consumer.huawei.com/en/community/details/Tokyo-Olympic-Games-Rely-on-Petal-Search-for-Highlights-and-Breaking-News/topicId_159041/">News.</a></li></p>
					
				<p><li style="font-size:15px;margin-bottom: -20px"> [Product] 07/2021, Check the new feature in HUAWEI Watch 3, 
					<a href="https://consumer.huawei.com/uk/community/details/HUAWEI-Watch-3-How-to-use-fall-detection-and-emergency-SOS-call/topicId_49430/">News.</a></li></p>
					
				<p><li style="font-size:15px;margin-bottom: -20px"> [Research] 06/2021, our team win the 2nd place in 2021 <a href="http://activity-net.org/challenges/2021/tasks/anet_localization.html">ActivityNet challenge</a>, 
					<a href="https://www.youtube.com/watch?v=FXbf7nb-S0w&t=1007s">presentation video</a>, [<a href="./projects/activitynet.html" target="_blank"><strong>Project Page</strong></a>].</li></p>
				<p><li style="font-size:15px;margin-bottom: -20px"> [Product] 2020, Video Labeling system for Video Content Tagging (VCT) <a href="https://www.huaweicloud.com/en-us/product/vct.html">URL</a>.</li></p>
				<p><li style="font-size:15px;margin-bottom: -20px"> [Research] 07/2020, two papers accepted by <a href="https://eccv2020.eu/">ECCV2020</a>.</li></p>
				<p><li style="font-size:15px"> [Product] 2018, Spotlight Reel is featured in the Huawei Release conference!! <a href="https://www.youtube.com/embed/jLD1BG0obXQ">Press</a>, <a href="https://www.youtube.com/watch?v=HQuYcwoHBrk">Commercial</a>, 
					<a href="http://dev3.noahlab.com.hk/huawei_mate20.html">News</a>
					</li></p> 
					<p align="center"><iframe width="320" height="215" 
						src="https://www.youtube.com/embed/jLD1BG0obXQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>
			 
			 
			<h2><span style="margin-bottom: -40px"><strong>Project Hightlights</strong></span></h2>
			 
			<span class="imgPusher" style="float:left;height:0px"></span><span style="display: table;width:auto;position:relative;float:left;max-width:100%;;clear:left;margin-top:0px;*margin-top:0px"><a>
				<img height="110" width="200" src="./projects/support/spotlight.png" style="margin-top: 5px; margin-bottom: 10px; margin-left: 0px; margin-right: 10px; border-width:1px;padding:3px; max-width:100%" alt="Picture" class="galleryImageBorder wsite-image"></a>
				<span style="display: table-caption; caption-side: bottom; font-size: 90%; margin-top: -10px; margin-bottom: 10px; text-align: center;" class="wsite-caption"></span></span>
				<p class="paragraph">
				<strong>Spotlight Reel</strong>, released in 2018
				 
				<br><a href="https://patents.google.com/patent/WO2020168998A1" target="_blank">Semi-supervised hybrid clustering/classification system</a><span style="color:rgb(42, 42, 42)">, <em>Patent No.: US11023710B2</em>.</span>
				<br><a href="https://patents.google.com/patent/WO2019174458A1/" target="_blank">Intelligent video interaction method</a><span style="color:rgb(42, 42, 42)">, <em>Patent No.: US10979761B2</em>.<br>
				 [<a href="http://dev3.noahlab.com.hk/huawei_mate20.html" target="_blank"><strong>News</strong></a>]
				 [<a href="https://www.youtube.com/embed/jLD1BG0obXQ" target="_blank"><strong>Press</strong></a>]
				 [<a href="https://www.facebook.com/watch/?v=436305406906020" target="_blank"><strong>Commercial</strong></a>]
				 [<a href="https://youtu.be/HQuYcwoHBrk" target="_blank"><strong>Commercial</strong></a>]
				 </span>
				 
				 <br>
				 <br>Mate 20 series mobile phone's unique identity-oriented AI video cutting function can extract the key segment of the specific main character. With various special effects, these clips are automatically compiled into wonderful movies about the character. 
				 Gather the bits you want and build your own blockbuster.</p>
				 
			
			<span class="imgPusher" style="float:left;height:0px"></span><span style="display: table;width:auto;position:relative;float:left;max-width:100%;;clear:left;margin-top:0px;*margin-top:0px">
				<a>
					<img height="110" width="200" src="./projects/support/activitynet2021.png" style="margin-top: 5px; margin-bottom: 10px; margin-left: 0px; margin-right: 10px; border-width:1px;padding:3px; max-width:100%" alt="Picture" class="galleryImageBorder wsite-image">
				</a>
					<span style="display: table-caption; caption-side: bottom; font-size: 90%; margin-top: -10px; margin-bottom: 10px; text-align: center;" class="wsite-caption"></span></span>
				<p class="paragraph">
				
				<strong>ActivityNet Challenge</strong>, 2021
				<br><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Sridhar_Class_Semantics-Based_Attention_for_Action_Detection_ICCV_2021_paper.pdf" target="_blank">Class Semantics-based Attention for Action Detection</a><span style="color:rgb(42, 42, 42)">, <em>ICCV2021.</em></span>
				<br><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750035.pdf" target="_blank">Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition</a><span style="color:rgb(42, 42, 42)">, <em>ECCV2020.</em></span>
				
				<br>
				[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Sridhar_Class_Semantics-Based_Attention_for_Action_Detection_ICCV_2021_paper.pdf" target="_blank">CSA </a>]
				[<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750035.pdf" target="_blank">C2F</a>] 
				[<a href="./projects/activitynet.html" target="_blank"><strong>Project Page</strong></a>]
				 
				<br><br>We won the 2nd place in 2021 ActivityNet Temporal Action Localization Challenge.</p>
			 
			
			<span class="imgPusher" style="float:left;height:0px"></span><span style="display: table;width:auto;position:relative;float:left;max-width:100%;;clear:left;margin-top:0px;*margin-top:0px">
				<a>
					<img height="110" width="200" src="./projects/support/sports.jpg" style="margin-top: 5px; margin-bottom: 10px; margin-left: 0px; margin-right: 10px; border-width:1px;padding:3px; max-width:100%" alt="Picture" class="galleryImageBorder wsite-image">
				</a>
					<span style="display: table-caption; caption-side: bottom; font-size: 90%; margin-top: -10px; margin-bottom: 10px; text-align: center;" class="wsite-caption"></span></span>
				<p class="paragraph">
				
				<strong>Sports Highlights</strong> for <a href="https://consumer.huawei.com/en/mobileservices/search/" target="_blank">Petal Search</a>, released in 2021
				<br>Patent filed
				 
				<br>
				[<a href="https://consumer.huawei.com/en/community/details/Tokyo-Olympic-Games-Rely-on-Petal-Search-for-Highlights-and-Breaking-News/topicId_159041/" target="_blank">News</a>]
				[<a href="https://consumer.huawei.com/za/community/details/Tokyo-Olympic-Games-Rely-on-Petal-Search-for-Highlightsand-Breaking-News/topicId_146359/" target="_blank">News (Tokyo Olympics)</a>]
				[<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750035.pdf" target="_blank">C2F</a>]
				[<a href="./projects/cpnet.html" target="_blank"><strong>CPNet</strong></a>]
				 
				<br><br>Open Petal Search and search for your favorite athletes and sports, and you'll find the latest news, event times, medal counts, athlete information, video highlights, and a wealth of other intriguing content.
				Whether you're interested in the stats and scores, or are following your favorite athletes, with Petal Search, there's no need to miss a moment of sports action!</p>
			
			
			<h2><strong>Past Experience</strong></h2>
			
			<p>From Jan 2015 to Dec 2016, I was with the Department of Computer Science, University of Western Ontario, also affiliated with Robarts Research Institute. 
			I worked on the modeling and detection of Alzheimer's Disease (AD) with <a href="http://cmhr.uwo.ca/mentors/bios/gwadry.html" target="_blank"> Dr. Femida Gwadry-Sridhar</a> and 
			<a href="http://www.csd.uwo.ca/~bauer/" target="_blank">Prof. Michael Bauer</a> as my Principal Investigators. I also worked closely with Prof. Michael Borrie.
			</p>
			

			<p>From Jan 2014 to Dec 2014, I worked as a Postdoctoral Fellow in Toronto Rehabilitation Institute (TRI), joint affiliated with the Department of Computer Science, University of Toronto. 
			TRI is a member of University Health Network (UHN) and is affiliated with the University of Toronto. University Health Network (UHN) is Canada's largest research hospital, 
			and a major teaching hospital of the University of Toronto. My supervisors were <a href="http://www.cs.toronto.edu/~frank/" target="_blank">Assit/P Frank Rudzicz</a> (Department of Computer Science, University of Toronto) and A/P Alex Mihailidis 
			(Dept of Occupational Science and Occupational Therapy & Institute of Biomaterials and Biomedical Engineering, University of Toronto).</p>

			<p>From July 2012 to Dec 2013, I worked as a Research Associate for <a href="https://sites.google.com/site/shenshyang/home" target="_blank">Assist/P Ho Shen-Shyang</a> in School of Computer Engineering (SCE) of Nanyang Technological University (NTU). 
			I was with the Center for Computational Intelligence (C2i).</p>
			
            
			
        </div>
      </div>
	  
	  
	  
      <div class="sidebar_container">
	  <p> </p>

		<p><b>"Education is not the learning of facts, but the training of the mind to think." </b></p>

		<p>-- Albert Einstein.</p>
		<div class="sidebar_twitter">
			<a class="twitter-timeline" href="https://twitter.com/PengDai_ca" data-widget-id="634733354391347200">Tweets by @PengDai_ca</a>
			<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
			</script>
		</div>
		
        <div class="sidebar">
          <div class="sidebar_top"></div>
          <div class="sidebar_item">
            <h2>Contact</h2>
			<p style="font-family:arial ">19 Allstate Pkwy, Markham, ON L3R 5A4 </p>
            <!-- <h4><span style="color: #444; width: 55px;float: left;">Address: </span> Middlesex College, Room 240A, The University of Western Ontario, London, ON, Canada N6A3K7</h4> -->

			<h4><span style="color: #444; width: 55px;float: left; ">Email:</span><a href="mailto:peng.dai.ca@ieee.org">peng.dai.ca@ieee.org</a></h4>
            <!-- <a href="http://twitter.com/"><img src="images/icons/twitter.png" alt="twitter" /></a><a href="http://www.facebook.com/"><img src="images/icons/facebook.png" alt="facebook" /></a><a href="http://uk.linkedin.com/"><img src="images/icons/linkedin.png" alt="linked in" /></a>
			-->
			<p></p>
			<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=RW6rojyVtksHZFRYlKSj6DNHyc3DbVsW0g1EGVa6s10&cl=ffffff&w=a"></script>
			
			<p></p>
			<div style="float:left; height: 181px; ; margin-right: 10px; padding: 5px;">
				<img  width="200" src="./images0/ieee_toronto.png" alt="image" />
				<br><img  width="180" src="./images0/ieee_cs.png" alt="image" />
				<br><img  width="200" src="./images0/acm.png" alt="image" />
				<br><img  width="200" src="./images0/Huawei_logo.png" alt="image" />
			</div>
			
          </div>
          <div class="sidebar_base"></div>
        </div>
        
      </div>
    </div>
	
	
    <div id="footer">
		<a href="https://scholar.google.ca/citations?user=pOpgtRgAAAAJ&hl=en" target="_blank">Google Scholar</a> |
		<a href="https://www.linkedin.com/in/peng-dai-6b426120/" target="_blank">LinkedIn</a> |
		<a href="https://twitter.com/PengDai_ca">Twitter</a> | 
		<a href="https://medium.com/@dperception">Medium</a> | 
		<a href="http://orcid.org/0000-0002-3015-7485#sthash.hZRZ9424.dpuf">ORCID</a>
    </div>
  </div>
  <p style="float: left;padding: 0;">&nbsp;</p>
  
</body>
</html>
